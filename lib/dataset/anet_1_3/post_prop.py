import os
import numpy as np
import pandas as pd
import json
import time
import argparse
import multiprocessing as mp
import pickle

from lib.utils.util import load_config
from lib.utils.tool import boundary_choose


def soft_nms(df, alpha=0.4, t1=0.5, t2=0.9, max_num=100):
    """
    df: proposals generated by network;
    alpha: alpha value of Gaussian decaying function;
    t1, t2: threshold for soft nms.
    """
    df = df.sort_values(by="score", ascending=False)
    tstart = list(df.xmin.values[:])
    tend = list(df.xmax.values[:])
    tscore = list(df.score.values[:])

    rstart = []
    rend = []
    rscore = []

    while len(tscore) > 1 and len(rscore) < max_num:
        max_index = tscore.index(max(tscore))
        tmp_start = tstart[max_index]
        tmp_end = tend[max_index]
        tmp_score = tscore[max_index]
        rstart.append(tmp_start)
        rend.append(tmp_end)
        rscore.append(tmp_score)
        tstart.pop(max_index)
        tend.pop(max_index)
        tscore.pop(max_index)

        tstart = np.array(tstart)
        tend = np.array(tend)
        tscore = np.array(tscore)

        tt1 = np.maximum(tmp_start, tstart)
        tt2 = np.minimum(tmp_end, tend)
        intersection = tt2 - tt1
        duration = tend - tstart
        tmp_width = tmp_end - tmp_start
        iou = intersection / (tmp_width + duration - intersection).astype(np.float)

        idxs = np.where(iou > t1 + (t2 - t1) * tmp_width)[0]
        tscore[idxs] = tscore[idxs] * np.exp(-np.square(iou[idxs]) / alpha)

        tstart = list(tstart)
        tend = list(tend)
        tscore = list(tscore)

    newDf = pd.DataFrame()
    newDf["score"] = rscore
    newDf["xmin"] = rstart
    newDf["xmax"] = rend
    return newDf


def getDatasetDict():
    df = pd.read_csv("./lib/dataset/anet_1_3/data/video_info_2020.csv")
    json_data = json.load(open("./lib/dataset/anet_1_3/data/activity_net_1_3_new.json"))
    database = json_data["database"]

    train_dict = {}
    val_dict = {}
    test_dict = {}
    for i in range(len(df)):
        video_name = df.video.values[i]
        video_info = database[video_name[2:]]
        video_new_info = {}
        video_new_info["duration_frame"] = df.duration_frame.values[i]
        video_new_info["duration_second"] = df.duration_second.values[i]
        video_subset = df.subset.values[i]
        video_new_info["annotations"] = video_info["annotations"]
        if video_subset == "training":
            train_dict[video_name] = video_new_info
        elif video_subset == "validation":
            val_dict[video_name] = video_new_info
        elif video_subset == "testing":
            test_dict[video_name] = video_new_info
    return train_dict, val_dict, test_dict


def _gen_detection_video(video_list, video_dict, cfg, num_prop=100):
    tscale = cfg.DATASET.tscale
    dscale = cfg.DATASET.dscale
    output_path = "./exps/{}/output/".format(cfg.EXP_NAME)

    anchor_xmin = np.array([i / tscale for i in range(tscale)])
    anchor_xmax = np.array([i / tscale for i in range(1, tscale + 1)])
    cols = ["xmin", "xmax", "score"]

    for video_name in video_list:
        file_path = os.path.join(output_path, "{}.pkl".format(video_name))

        with open(file_path, "rb") as infile:
            result = pickle.load(infile)

        [_, pred_local_s, pred_local_e, pred_global_s, pred_global_e, pred_iou_map] = result

        pred_s = np.sqrt(pred_local_s * pred_global_s)
        pred_e = np.sqrt(pred_local_e * pred_global_e)
        pred_iou_map = pred_iou_map[0, :, :] * pred_iou_map[1, :, :]

        start_mask = boundary_choose(pred_s)
        start_mask[0] = 1.0
        end_mask = boundary_choose(pred_e)
        end_mask[-1] = 1.0

        score_vector_list = []
        for idx in range(dscale):
            for jdx in range(tscale - idx):
                start_idx = jdx
                end_idx = start_idx + idx
                if start_mask[start_idx] == 1 and end_mask[end_idx] == 1:
                    xmin = anchor_xmin[start_idx]
                    xmax = anchor_xmax[end_idx]
                    xmin_score = pred_s[start_idx]
                    xmax_score = pred_e[end_idx]
                    conf_score = xmin_score * xmax_score * pred_iou_map[idx, jdx]
                    score_vector_list.append([xmin, xmax, conf_score])

        score_vector_list = np.stack(score_vector_list)
        df = pd.DataFrame(score_vector_list, columns=cols)

        if len(df) > 1:
            df = soft_nms(
                df,
                alpha=cfg.PROPOSAL_POST.alpha,
                t1=cfg.PROPOSAL_POST.t1,
                t2=cfg.PROPOSAL_POST.t2,
            )

        df = df.sort_values(by="score", ascending=False)

        video_duration = video_dict[video_name]["duration_second"]
        proposal_list = []
        for j in range(min(num_prop, len(df))):
            tmp_proposal = {}
            tmp_proposal["score"] = df.score.values[j]
            tmp_proposal["segment"] = [
                max(0, df.xmin.values[j]) * video_duration,
                min(1, df.xmax.values[j]) * video_duration,
            ]
            proposal_list.append(tmp_proposal)
        result_dict[video_name[2:]] = proposal_list


def gen_proposal_multicore(cfg):
    # get video list
    train_dict, val_dict, test_dict = getDatasetDict()
    video_dict = val_dict  # val_dict  test_dict
    video_list = list(video_dict.keys())

    global result_dict
    result_dict = mp.Manager().dict()

    # multi processing
    pp_num = 32
    num_videos = len(video_list)
    num_videos_per_thread = num_videos / pp_num
    processes = []
    for tid in range(pp_num - 1):
        tmp_video_list = video_list[int(tid * num_videos_per_thread) : int((tid + 1) * num_videos_per_thread)]
        p = mp.Process(target=_gen_detection_video, args=(tmp_video_list, video_dict, cfg))
        p.start()
        processes.append(p)
    tmp_video_list = video_list[int((pp_num - 1) * num_videos_per_thread) :]
    p = mp.Process(target=_gen_detection_video, args=(tmp_video_list, video_dict, cfg))

    p.start()
    processes.append(p)
    for p in processes:
        p.join()

    # write file
    result_dict = dict(result_dict)
    output_dict = {
        "version": "ActivityNet 1.3",
        "results": result_dict,
        "external_data": {},
    }

    with open(cfg.result_path, "w") as out:
        json.dump(output_dict, out)


def proposal_post(cfg):
    cfg.output_path = "./exps/%s/output/" % (cfg.EXP_NAME)
    cfg.result_path = "./exps/%s/result_proposal.json" % (cfg.EXP_NAME)

    # post processing
    t1 = time.time()
    print("\nProposal task post processing start")
    gen_proposal_multicore(cfg)
    t2 = time.time()
    print("Proposal task Post processing finished, time=%.1fmins\n" % ((t2 - t1) / 60))

    # evaluation
    from lib.eval.eval_proposal import ANETproposal

    tious = np.linspace(0.5, 0.95, 10)
    anet_proposal = ANETproposal(
        ground_truth_filename="./lib/dataset/anet_1_3/data/activity_net_1_3_new.json",
        proposal_filename=cfg.result_path,
        tiou_thresholds=tious,
        subset="validation",
    )

    recall, auc = anet_proposal.evaluate()

    print("AR@1 is \t{:.4f}".format(np.mean(recall[:, 0])))
    print("AR@5 is \t{:.4f}".format(np.mean(recall[:, 4])))
    print("AR@10 is \t{:.4f}".format(np.mean(recall[:, 9])))
    print("AR@100 is \t{:.4f}".format(np.mean(recall[:, -1])))

    # save to files
    cfg.eval_path = "./exps/%s/results.txt" % (cfg.EXP_NAME)
    f2 = open(cfg.eval_path, "a")
    f2.write("\t AUC: {}\n".format(auc))
    f2.write("AR@1 is \t{:.4f}\n".format(np.mean(recall[:, 0])))
    f2.write("AR@5 is \t{:.4f}\n".format(np.mean(recall[:, 4])))
    f2.write("AR@10 is \t{:.4f}\n".format(np.mean(recall[:, 9])))
    f2.write("AR@100 is \t{:.4f}\n".format(np.mean(recall[:, -1])))
    f2.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="BMN")
    parser.add_argument(
        "config",
        metavar="FILE",
        help="path to config file",
        type=str,
    )
    args = parser.parse_args()

    # load settings
    cfg = load_config(args.config)

    # post process
    proposal_post(cfg)
